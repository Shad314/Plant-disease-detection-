{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CNN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "U40rcoMLeeLD"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcis21vXeeys",
        "outputId": "d98274b2-a7c5-4795-dac7-c368ddf311f2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path1 = \"/content/gdrive/MyDrive/Train/diseased\""
      ],
      "metadata": {
        "id": "0oZ5VdQWehsZ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path2 = \"/content/gdrive/MyDrive/Train/healthy\""
      ],
      "metadata": {
        "id": "nrNONShhej9p"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2\n",
        "import glob\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import torch.nn.functional as Func\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "JZx9BGvAetgg"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "train = []\n",
        "test = []\n",
        "l = [0,0]\n",
        "\n",
        "c = 0\n",
        "\n",
        "for filename in os.listdir(path1):\n",
        "  filename = path1 + \"/\" + filename\n",
        "  if c > 564:\n",
        "    l[0] = 1\n",
        "    test.append([filename,l])\n",
        "    c += 1\n",
        "  else:\n",
        "    l[0] = 1\n",
        "    train.append([filename,l])\n",
        "    c += 1"
      ],
      "metadata": {
        "id": "HvzROWl7ekcg"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "l = [0,0]\n",
        "\n",
        "c = 0\n",
        "\n",
        "for filename in os.listdir(path2):\n",
        "  filename = path2 + \"/\" + filename\n",
        "  if c > 654:\n",
        "    l[1] = 1\n",
        "    test.append([filename,l])\n",
        "    c += 1\n",
        "  else:\n",
        "    l[1] = 1\n",
        "    train.append([filename,l])\n",
        "    c += 1"
      ],
      "metadata": {
        "id": "LsnBfeKDemfR"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(Dataset):\n",
        "    \n",
        "\n",
        "    def __init__(self, train, root_dir, transform=None):\n",
        "        \n",
        "        self.landmarks_frame = train\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.landmarks_frame)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        img_name = os.path.join(self.root_dir,self.landmarks_frame[idx][0])\n",
        "        image = cv2.imread(img_name)\n",
        "        y = torch.tensor(self.landmarks_frame[idx][1])\n",
        "        y = y.float()\n",
        "        \n",
        "        \n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return (image,y)"
      ],
      "metadata": {
        "id": "CLtrN5lNeoxw"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(train))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S8SZAKOWeveI",
        "outputId": "bf0f23f9-2d8c-4c9b-d09b-0b344aab8502"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1220\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fJBassOHewDI",
        "outputId": "a2b07f37-d28c-45da-b83c-6691c5d4e291"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "519\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "8lVBjWj8fse8"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = Dataset(train = train,root_dir='', transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(256, transforms.InterpolationMode.BICUBIC),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "]))"
      ],
      "metadata": {
        "id": "5h0UasI1exxx"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_dataset = Dataset(train = test,root_dir='', transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Resize(256, transforms.InterpolationMode.BICUBIC),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "\n",
        "]))"
      ],
      "metadata": {
        "id": "bsFPfHnxezzB"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_classes = 2\n",
        "batch_size = 8\n",
        "num_epochs = 20"
      ],
      "metadata": {
        "id": "_2UHnAQSe1nY"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainloader = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size)\n",
        "\n",
        "testloader = torch.utils.data.DataLoader(test_dataset, shuffle=True, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "EXk6cad6e3rw"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ConvNet_SGD(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ConvNet_SGD, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(4, 4)\n",
        "        self.pool2 = nn.MaxPool2d(3,3)\n",
        "        self.conv2 = nn.Conv2d(6, 10, 4)\n",
        "        self.conv3 = nn.Conv2d(10,20, 4)\n",
        "        self.fc1 = nn.Linear(20*4*4, 120)\n",
        "        self.fc2 = nn.Linear(120, 10)\n",
        "        self.fc3= nn.Linear(10,2)\n",
        " \n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.pool(self.conv1(x))  \n",
        "        x = self.pool(self.conv2(x))  \n",
        "        x=  self.pool2(self.conv3(x))\n",
        "        x = x.view(-1, 20*4*4)           \n",
        "        x = Func.relu(self.fc1(x))              \n",
        "        x = self.fc2(x)         \n",
        "        x = self.fc3(x)    \n",
        "        return x"
      ],
      "metadata": {
        "id": "8oqCnCGPe5qw"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ConvNet_SGD().to(device)"
      ],
      "metadata": {
        "id": "BxRb2-5ke7Uw"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
        "num_epochs=20"
      ],
      "metadata": {
        "id": "wAMX7hb5e9Dw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "losses = []"
      ],
      "metadata": {
        "id": "C5HzOqdcmLSI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model):\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
        "        print('-' * 10)\n",
        "\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, labels in trainloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        " \n",
        "\n",
        " \n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            with torch.set_grad_enabled(True):\n",
        "            \n",
        "              outputs = model(inputs)\n",
        "    \n",
        "              loss = criterion(outputs, labels)\n",
        "\n",
        "              _, preds = torch.max(outputs, 1)\n",
        "              loss.backward()\n",
        "              optimizer.step()\n",
        "\n",
        "\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "              \n",
        "\n",
        "        epoch_loss = running_loss / len(trainloader.dataset)\n",
        "        print('Loss: {:.4f} '.format(epoch_loss))\n",
        "        losses.append(epoch_loss)"
      ],
      "metadata": {
        "id": "yd6ahrGqfJ7B"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDVAR8ZamQwN",
        "outputId": "03ac3781-8e65-4ec5-8ee5-24a605d70d18"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/9\n",
            "----------\n",
            "Loss: 0.6841 \n",
            "Epoch 1/9\n",
            "----------\n",
            "Loss: 0.5196 \n",
            "Epoch 2/9\n",
            "----------\n",
            "Loss: 0.3340 \n",
            "Epoch 3/9\n",
            "----------\n",
            "Loss: 0.2516 \n",
            "Epoch 4/9\n",
            "----------\n",
            "Loss: 0.2185 \n",
            "Epoch 5/9\n",
            "----------\n",
            "Loss: 0.1729 \n",
            "Epoch 6/9\n",
            "----------\n",
            "Loss: 0.1402 \n",
            "Epoch 7/9\n",
            "----------\n",
            "Loss: 0.1399 \n",
            "Epoch 8/9\n",
            "----------\n",
            "Loss: 0.1176 \n",
            "Epoch 9/9\n",
            "----------\n",
            "Loss: 0.1301 \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "IKXcVTW3CLwA"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot( losses,color='blue', label= \"Train_Loss\", linewidth=2)\n",
        "plt.ylabel('Train Loss')\n",
        "plt.xlabel('Number of Epochs')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "id": "JMpeXtKSB22g",
        "outputId": "61ad66dd-ff2b-4d0f-cf6c-96fc5863367b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Number of Epochs')"
            ]
          },
          "metadata": {},
          "execution_count": 6
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Predicted = []\n",
        "Lab = []"
      ],
      "metadata": {
        "id": "2CugkT6pg4ih"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "\n",
        "        images = images.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = model(images)\n",
        "\n",
        "\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "\n",
        "        _, lab = torch.max(labels , 1)\n",
        "        for x in range(len(predicted)):\n",
        "          Predicted.append(int(predicted[x]))\n",
        "          Lab.append(int(lab[x]))\n",
        "\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == lab).sum().item()\n",
        "\n",
        "print(f'Accuracy of the network on the test images: {100 * correct // total} %')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2PakfTPhfN7g",
        "outputId": "7c64b38f-c972-4ac8-e38b-8c76753b91a6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy of the network on the test images: 93 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_true = Lab\n",
        "y_pred = Predicted\n",
        "target_names = ['class' + str(x) for x in range(2)]\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yYH1PyYrnSC4",
        "outputId": "f47b6677-9ae4-4e00-9d80-cfe36b764495"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      class0       0.91      0.96      0.93       240\n",
            "      class1       0.96      0.92      0.94       279\n",
            "\n",
            "    accuracy                           0.94       519\n",
            "   macro avg       0.94      0.94      0.94       519\n",
            "weighted avg       0.94      0.94      0.94       519\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "2OrqaiT9-oNY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}